{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a829403a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from utilities import files\n",
    "import os.path as op\n",
    "from os import sep\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm, colors\n",
    "from mne import read_epochs, pick_types\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tools import transform_atlas, fsavg_vals_to_native\n",
    "import new_files\n",
    "import json\n",
    "from mne.time_frequency import psd_array_multitaper, psd_array_welch\n",
    "\n",
    "from fooof.sim.gen import gen_aperiodic\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e510c9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_csd(surf_tcs, times, mean_dist, n_surfs):\n",
    "    # Compute CSD\n",
    "    nd=1;\n",
    "    spacing=mean_dist*10**-3\n",
    "\n",
    "    csd=np.zeros((n_surfs, surf_tcs.shape[1]))\n",
    "    for t in range(surf_tcs.shape[1]):\n",
    "        phi=surf_tcs[:,t]\n",
    "        csd[0,t]=surf_tcs[0,t]\n",
    "        csd[1,t]=surf_tcs[1,t]\n",
    "        for z in range(2,n_surfs-3):\n",
    "            csd[z,t]=(phi[z+2]-2*phi[z]+phi[z-2])/((nd*spacing)**2)\n",
    "        csd[-2,t]=surf_tcs[-2,t]\n",
    "        csd[-1,t]=surf_tcs[-1,t]            \n",
    "    \n",
    "    return csd\n",
    "\n",
    "\n",
    "def smooth_csd(csd, n_surfs):\n",
    "    # interpolate CSD in space\n",
    "    y = np.linspace(0,n_surfs-1,n_surfs)\n",
    "    Yi=np.linspace(0,n_surfs-1,500)\n",
    "    \n",
    "    f=interp1d(y,csd,kind='cubic',axis=0)\n",
    "    csd_smooth=f(Yi)\n",
    "    \n",
    "    csd_smooth=savgol_filter(csd_smooth, 51, 3, axis=1)\n",
    "    \n",
    "    return csd_smooth\n",
    "\n",
    "\n",
    "def compute_rel_power(power, freqs):\n",
    "    power = gaussian_filter(power, sigma=[1.5, 2])\n",
    "\n",
    "    if np.min(power[:]) < 0:\n",
    "        power = power - np.min(power[:])\n",
    "    rel_power = np.zeros(power.shape)\n",
    "    for freq in range(len(freqs)):\n",
    "        rel_power[:, freq] = (power[:, freq] - np.min(power[:, freq])) / (\n",
    "                    np.max(power[:, freq]) - np.min(power[:, freq]))\n",
    "\n",
    "    return rel_power\n",
    "\n",
    "\n",
    "def get_crossover(freqs,rel_per_power,rel_aper_power):\n",
    "    n_chans=rel_per_power.shape[0]\n",
    "    ab_idx = np.where((freqs >= 7) & (freqs <= 30))[0]\n",
    "    g_idx = np.where((freqs >= 50) & (freqs <= 125))[0]\n",
    "    ab_rel_pow = np.mean(rel_per_power[:, ab_idx], axis=1)\n",
    "    g_rel_pow = np.mean(rel_aper_power[:, g_idx], axis=1)\n",
    "    crossovers = detect_crossing_points(ab_rel_pow, g_rel_pow)\n",
    "    assert(len(crossovers)<=2)\n",
    "    if len(crossovers) > 1:\n",
    "        dist1 = np.min([crossovers[0], n_chans - crossovers[0]])\n",
    "        dist2 = np.min([crossovers[1], n_chans - crossovers[1]])\n",
    "        if dist1 > dist2:\n",
    "            crossover = crossovers[0]\n",
    "        else:\n",
    "            crossover = crossovers[1]\n",
    "    else:\n",
    "        crossover = crossovers[0]\n",
    "    return crossover\n",
    "\n",
    "\n",
    "def detect_crossing_points(ab_rel_pow, g_rel_pow):\n",
    "    crossing_points = []\n",
    "\n",
    "    # Iterate through the series\n",
    "    for i in range(1, len(ab_rel_pow)):\n",
    "        # Check if the series cross each other\n",
    "        if (ab_rel_pow[i] > g_rel_pow[i] and ab_rel_pow[i - 1] < g_rel_pow[i - 1]) or \\\n",
    "                (ab_rel_pow[i] < g_rel_pow[i] and ab_rel_pow[i - 1] > g_rel_pow[i - 1]):\n",
    "            crossing_points.append(i)\n",
    "\n",
    "    return crossing_points\n",
    "\n",
    "\n",
    "def all_layers_ROI_map(layer_len, n_surf, ROI_indexes):\n",
    "    return np.array([i[ROI_indexes] for i in np.split(np.arange(layer_len*n_surf), n_surf)]).flatten()\n",
    "\n",
    "\n",
    "def fooofinator_par(freqs, psd, f_lims, n_jobs=-1):\n",
    "    start_params=np.arange(f_lims[0],f_lims[1]-5,1)\n",
    "    \n",
    "    def run_fooof(i):\n",
    "        start=start_params[i]\n",
    "        fg=FOOOF(aperiodic_mode='fixed')\n",
    "        fg.fit(freqs,psd, [start,f_lims[1]])\n",
    "        if fg.has_model:\n",
    "            ap_params=fg.get_params('aperiodic_params')\n",
    "            return gen_aperiodic(freqs, ap_params)\n",
    "        else:\n",
    "            return np.zeros(psd.shape)*np.nan\n",
    "    aperiodic = Parallel(\n",
    "        n_jobs=n_jobs\n",
    "    )(delayed(run_fooof)(i) for i in range(len(start_params)))\n",
    "    return np.nanmedian(np.array(aperiodic),axis=0)\n",
    "\n",
    "\n",
    "def fooofinator(freqs, psd, f_lims):\n",
    "    start_params=np.arange(f_lims[0],f_lims[1]-5,1)\n",
    "    test_aperiodic=[]\n",
    "    for i,start in enumerate(start_params):\n",
    "        fg=FOOOF(aperiodic_mode='fixed')\n",
    "        fg.fit(freqs,psd, [start,f_lims[1]])\n",
    "        if fg.has_model:\n",
    "            ap_params=fg.get_params('aperiodic_params')\n",
    "            test_aperiodic.append(gen_aperiodic(freqs, ap_params))\n",
    "    return np.median(np.array(test_aperiodic),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa69975",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/ses-01\"\n",
    "inverted_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/inverted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c2a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_paths = [\n",
    "    \"/home/mszul/git/DANC_multilayer_laminar/assets/lh.HCPMMP1.annot\",\n",
    "    \"/home/mszul/git/DANC_multilayer_laminar/assets/rh.HCPMMP1.annot\"\n",
    "]\n",
    "fsavg_sphere_paths = [\n",
    "    \"/home/mszul/git/DANC_multilayer_laminar/assets/lh.sphere.reg.gii\",\n",
    "    \"/home/mszul/git/DANC_multilayer_laminar/assets/rh.sphere.reg.gii\"\n",
    "]\n",
    "fsnat_sphere_paths = [\n",
    "    \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/lh.sphere.reg.gii\",\n",
    "    \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/rh.sphere.reg.gii\"\n",
    "]\n",
    "pial_path = \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/pial.gii\"\n",
    "pial_ds_path = \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/pial.ds.gii\"\n",
    "pial_ds_nodeep = \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/pial.ds.link_vector.nodeep.gii\"\n",
    "pial_ds_inflated = \"/home/common/bonaiuto/cued_action_meg/derivatives/processed/sub-001/fs/surf/pial.ds.inflated.nodeep.gii\"\n",
    "glasser = \"/home/mszul/git/DANC_multilayer_laminar/assets/atlas_glasser_2016.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb131c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_surf = 11\n",
    "atlas = pd.read_csv(glasser)\n",
    "ml_nodeep = nb.load(\"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/multilayer_11.ds.link_vector.nodeep.gii\");\n",
    "vertices, faces, normals = ml_nodeep.agg_data()\n",
    "vertices = np.split(vertices, n_surf, axis=0)\n",
    "faces = np.split(faces, n_surf, axis=0)\n",
    "normals = np.split(normals, n_surf, axis=0)\n",
    "layer_len = vertices[0].shape[0]\n",
    "nufs = new_files.Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dabccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflated_nodeep = nb.load(\"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/pial.ds.inflated.nodeep.gii\")\n",
    "i_vertices, i_faces = inflated_nodeep.agg_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6938b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_col_map_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/glasser2006_labels_per_vertex.npy\"\n",
    "mesh_colors_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/glasser2006_colours_per_vertex.npy\"\n",
    "cortical_thickness_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/cortical_thickness_vertex.npy\"\n",
    "bigbrain_boundaries_list_path = \"/home/common/bonaiuto/multiburst/derivatives/processed/sub-001/multilayer_11/big_brain_boundaries.json\"\n",
    "\n",
    "\n",
    "if not all([op.exists(lab_col_map_path), op.exists(mesh_colors_path)]):\n",
    "    mesh_colors, lab_col_map = transform_atlas(annot_paths, fsavg_sphere_paths, fsnat_sphere_paths, pial_path, pial_ds_path, pial_ds_nodeep)\n",
    "    np.save(lab_col_map_path, lab_col_map)\n",
    "    np.save(mesh_colors_path, mesh_colors)\n",
    "elif all([op.exists(lab_col_map_path), op.exists(mesh_colors_path)]):\n",
    "    mesh_colors = np.load(mesh_colors_path)\n",
    "    lab_col_map = np.load(lab_col_map_path)\n",
    "\n",
    "if not all([op.exists(cortical_thickness_path)]):\n",
    "    cortical_thickness = np.array([euclidean(vertices[0][vx], vertices[-1][vx]) for vx in range(vertices[0].shape[0])])\n",
    "    np.save(cortical_thickness_path, cortical_thickness)\n",
    "elif all([op.exists(cortical_thickness_path)]):\n",
    "    cortical_thickness = np.load(cortical_thickness_path)\n",
    "\n",
    "\n",
    "if not all([op.exists(bigbrain_boundaries_list_path)]):\n",
    "    bigbrain_l_paths = nufs.get_files(\"/home/mszul/git/DANC_multilayer_laminar/assets/big_brain_layer_thickness\", \"*.gii\", strings=[\"hemi-L\"], prefix=\"tpl-fsaverage\")\n",
    "    bigbrain_r_paths = nufs.get_files(\"/home/mszul/git/DANC_multilayer_laminar/assets/big_brain_layer_thickness\", \"*.gii\", strings=[\"hemi-R\"], prefix=\"tpl-fsaverage\")\n",
    "    bigbrain_lr_paths = list(zip(thicc_l_paths, thicc_r_paths))\n",
    "    layers_fsaverage_values = {i+1: [nb.load(i).agg_data() for i in bigbrain_lr_paths[i]] for i in range(len(bigbrain_lr_paths))}\n",
    "    layers_fsnative_ds_values = {i: fsavg_vals_to_native(\n",
    "        layers_fsaverage_values[i],\n",
    "        fsavg_sphere_paths,\n",
    "        fsnat_sphere_paths, \n",
    "        pial_path, \n",
    "        pial_ds_path, \n",
    "        pial_ds_nodeep\n",
    "    ) for i in layers_fsaverage_values.keys()}\n",
    "\n",
    "    overall_thickness = np.sum(layers, axis=0)\n",
    "    bigbrain_boundaries_prop = {i: np.divide(\n",
    "        layers_fsnative_ds_values[i], \n",
    "        overall_thickness, \n",
    "        where=overall_thickness != 0\n",
    "    ) for i in layers_fsnative_ds_values.keys()}\n",
    "\n",
    "    np.save(\n",
    "        lab_col_map_path,\n",
    "        lab_col_map\n",
    "    )\n",
    "    np.save(\n",
    "        mesh_colors_path,\n",
    "        mesh_colors\n",
    "    )\n",
    "    np.save(\n",
    "        cortical_thickness_path,\n",
    "        cortical_thickness\n",
    "    )\n",
    "\n",
    "    bigbrain_boundaries_list = {i: list(bigbrain_boundaries_prop[i].astype(float)) for i in bigbrain_boundaries_prop.keys()}\n",
    "    with open(bigbrain_boundaries_list_path, \"w\") as fp:\n",
    "        json.dump(bigbrain_boundaries_list, fp, indent=4)\n",
    "\n",
    "elif all([op.exists(bigbrain_boundaries_list_path)]):\n",
    "    with open(bigbrain_boundaries_list_path, \"r\") as fp:\n",
    "        bigbrain_boundaries_list = json.load(fp)\n",
    "    bigbrain_boundaries_list = {i: np.array(bigbrain_boundaries_list[i]) for i in bigbrain_boundaries_list.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4772d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_maps = {i: [i == j.decode(\"utf=8\") for j in lab_col_map] for i in atlas.USED_LABEL.values}\n",
    "ROI_indexes = {i: np.arange(layer_len)[ROI_maps[i]] for i in ROI_maps.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee124855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L_4_ROI', 'L_3b_ROI', 'L_1_ROI', 'L_2_ROI', 'L_3a_ROI']\n"
     ]
    }
   ],
   "source": [
    "target_ROI = atlas.loc[(atlas.PRIMARY_SECTION == 6) & (atlas.HEMISPHERE == \"L\")].USED_LABEL.tolist()\n",
    "print(target_ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8471af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_combined_map = np.hstack([ROI_indexes[i] for i in target_ROI])\n",
    "ROI_combined_map.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249682e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_combined_map = np.random.choice(ROI_combined_map, size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377cd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    \"visual\": (-0.2, 0.8),\n",
    "    \"motor\": (-0.5, 0.5)\n",
    "}\n",
    "\n",
    "times = {}\n",
    "crop_times = {}\n",
    "n_surf = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb5cb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_paths = files.get_files(raw_path, \"autoreject\", \"epo.fif\")[2]\n",
    "MU_paths = files.get_files(inverted_path, \"MU\", \".tsv\")[2]\n",
    "fif_MU = list(zip(fif_paths, MU_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fe70501",
   "metadata": {},
   "outputs": [],
   "source": [
    "fif, MU = fif_MU[0]\n",
    "core_name = fif.split(sep)[-1].split(\".\")[0].replace(\"autoreject-\", \"\")\n",
    "epo_type = [i for i in info.keys() if i in core_name][0]\n",
    "crop_time = info[epo_type]\n",
    "fif = read_epochs(fif, verbose=False)\n",
    "fif = fif.pick_types(meg=True, ref_meg=False, misc=False)\n",
    "times[epo_type] = fif.times\n",
    "sfreq = fif.info[\"sfreq\"]\n",
    "fif = fif.get_data()\n",
    "MU = pd.read_csv(MU, sep=\"\\t\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8a0ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilayer_vert = np.split(np.arange(layer_len *n_surf), n_surf)\n",
    "ROI_verts = np.hstack([i[ROI_combined_map] for i in multilayer_vert])\n",
    "MU_roi = MU[ROI_verts]\n",
    "source = []\n",
    "for trial in fif:\n",
    "    trial_source = np.dot(trial.T, MU_roi.T).T\n",
    "    trial_source = np.split(trial_source, n_surf, axis=0)\n",
    "    trial_source = np.array(trial_source) # layer x vertex x time\n",
    "    source.append(trial_source)\n",
    "source = np.array(source) # trial x layer x vertex x time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# psd_per_layer = []\n",
    "# periodic_per_layer = []\n",
    "# aperiodic_per_layer = []\n",
    "# fooofed_spec_per_layer = []\n",
    "# for surf in range(n_surf):\n",
    "#     winsize = int(sfreq)\n",
    "#     overlap = int(winsize/2)   \n",
    "#     psd,freqs = psd_array_welch(\n",
    "#         source[:, surf, :, :], sfreq,\n",
    "#         fmin=0.1, fmax=125, n_fft=2000,\n",
    "#         n_overlap=overlap, n_per_seg=winsize, \n",
    "#         window=\"hann\", verbose=False         \n",
    "#     )\n",
    "#     mean_psd = np.nanmean(psd,axis=0)\n",
    "#     psd_per_layer.append(mean_psd)\n",
    "#     fg = FOOOFGroup(aperiodic_mode=\"fixed\")\n",
    "#     fg.fit(freqs, mean_psd, [0.1,125])\n",
    "#     ap_vx = 10 ** np.array([fg.get_fooof(i)._ap_fit for i in range(mean_psd.shape[0])]) # results stored in linear scale\n",
    "#     ff_spec_vx = 10 ** np.array([fg.get_fooof(i)._ap_fit for i in range(mean_psd.shape[0])]) # results stored in linear scale\n",
    "#     pr_vx = mean_psd - ap_vx\n",
    "#     aperiodic_per_layer.append(ap_vx)\n",
    "#     fooofed_spec_per_layer.append(ff_spec_vx)\n",
    "#     periodic_per_layer.append(pr_vx)\n",
    "\n",
    "# vx_r = range(psd_per_layer.shape[1])\n",
    "# psd_per_layer = np.array(psd_per_layer) # layer x vertex x freqs\n",
    "# periodic_per_layer = np.array(periodic_per_layer) # layer x vertex x freqs\n",
    "# aperiodic_per_layer = np.array(aperiodic_per_layer) # layer x vertex x freqs\n",
    "# fooofed_spec_per_layer = np.array(fooofed_spec_per_layer) # layer x vertex x freqs\n",
    "# psd_rel_power = np.stack([compute_rel_power(psd_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "# periodic_rel_power = np.stack([compute_rel_power(periodic_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "# aperiodic_rel_power = np.stack([compute_rel_power(aperiodic_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "# fooofed_rel_power = np.stack([compute_rel_power(fooofed_spec_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "# crossover = []\n",
    "# for i in vx_r:\n",
    "#     try:\n",
    "#         c = get_crossover(freqs, periodic_rel_power[:,i,:], aperiodic_rel_power[:,i,:])\n",
    "#     except:\n",
    "#         c = np.nan\n",
    "#     crossover.append(c)\n",
    "# crossover = np.array(crossover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5539fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "vx_r = range(source.shape[2])\n",
    "psd_per_layer = []\n",
    "periodic_per_layer = []\n",
    "aperiodic_per_layer = []\n",
    "flims = [0.1,125]\n",
    "for surf in range(n_surf):\n",
    "    winsize = int(sfreq)\n",
    "    overlap = int(winsize/2)   \n",
    "    psd,freqs = psd_array_welch(\n",
    "        source[:, surf, :, :], sfreq,\n",
    "        fmin=flims[0], fmax=flims[1], n_fft=2000,\n",
    "        n_overlap=overlap, n_per_seg=winsize, \n",
    "        window=\"hann\", verbose=False         \n",
    "    )\n",
    "    mean_psd = np.nanmean(psd,axis=0)\n",
    "    aperiodic = np.vstack([fooofinator_par(freqs, i, flims, n_jobs=-1) for i in mean_psd])\n",
    "    mean_psd = np.log10(mean_psd)\n",
    "    psd_per_layer.append(mean_psd)\n",
    "    periodic = mean_psd - aperiodic\n",
    "    periodic_per_layer.append(periodic)\n",
    "    aperiodic_per_layer.append(aperiodic)\n",
    "    print(surf)\n",
    "\n",
    "psd_per_layer = np.array(psd_per_layer) # layer x vertex x freqs\n",
    "periodic_per_layer = np.array(periodic_per_layer) # layer x vertex x freqs\n",
    "aperiodic_per_layer = np.array(aperiodic_per_layer) # layer x vertex x freqs\n",
    "psd_rel_power = np.stack([compute_rel_power(psd_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "periodic_rel_power = np.stack([compute_rel_power(periodic_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n",
    "aperiodic_rel_power = np.stack([compute_rel_power(aperiodic_per_layer[:,i,:], freqs) for i in vx_r], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b53620",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crossover = []\n",
    "for i in vx_r:\n",
    "    try:\n",
    "        c = get_crossover(freqs, periodic_rel_power[:,i,:], aperiodic_rel_power[:,i,:])\n",
    "    except:\n",
    "        c = np.nan\n",
    "    crossover.append(c)\n",
    "crossover = np.array(crossover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_ix = np.where((times[epo_type] >= crop_time[0]) & (times[epo_type] <= crop_time[-1]))[0]\n",
    "source_mean = np.mean(source[:,:,:,crop_ix], axis=0)\n",
    "crop_times[epo_type] = times[epo_type][crop_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_range = np.arange(crossover.shape[0])\n",
    "vx_crossover = vertices_range[~np.isnan(crossover)]\n",
    "vx_no_crossover = vertices_range[np.isnan(crossover)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_labels = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\"]\n",
    "\n",
    "vertex = vx_crossover[1]\n",
    "print(vertex)\n",
    "cov = crossover[vertex]/10\n",
    "thickness_vx = cortical_thickness[ROI_combined_map][vertex]\n",
    "mean_thickness_vx = thickness_vx/n_surf\n",
    "csd = compute_csd(source_mean[:, vertex, :], crop_times[epo_type], mean_thickness_vx, n_surf)\n",
    "csd_smooth = smooth_csd(csd, n_surf)\n",
    "f, ax = plt.subplots(1,4, figsize=(16,4))\n",
    "ax[0].set_title(\"Aperiodic Spectrum- relative power\")\n",
    "ax[0].imshow(aperiodic_rel_power[:,vertex,:], aspect=\"auto\", extent=[freqs[0], freqs[-1], 1, 0])\n",
    "ax[0].set_xlabel('Frequency (Hz)')\n",
    "ax[0].set_ylabel('Depth as a proportion of\\nthe overall cortical thickness')\n",
    "ax[0].axvline(7, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "ax[0].axvline(30, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "ax[0].axvline(50, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "ax[0].axhline(cov, lw=1, c=\"white\")\n",
    "# ax[0].set_ylim(1,0)\n",
    "ax[1].set_title(\"Periodic Spectrum- relative power\")\n",
    "ax[1].imshow(periodic_rel_power[:,vertex,:], aspect=\"auto\", extent=[freqs[0], freqs[-1], 1, 0])\n",
    "ax[1].set_xlabel('Frequency (Hz)')\n",
    "ax[1].axvline(7, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "ax[1].axvline(30, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "ax[1].axvline(50, linestyle=\"dashed\", lw=1, c=\"white\")\n",
    "# ax[1].set_ylim(1,0)\n",
    "ax[1].axhline(cov, lw=1, c=\"white\")\n",
    "ab_idx = np.where((freqs >= 7) & (freqs <= 30))[0]\n",
    "g_idx = np.where((freqs >= 50) & (freqs <= 125))[0]\n",
    "ab_rel_pow = np.mean(periodic_rel_power[:, vertex, ab_idx], axis=1)\n",
    "g_rel_pow = np.mean(aperiodic_rel_power[:, vertex, g_idx], axis=1)\n",
    "ax[2].set_title(\"Alpha-Beta vs Gamma crossover\")\n",
    "ax[2].plot(ab_rel_pow,np.arange(periodic_rel_power.shape[0])/10,label='apha-beta')\n",
    "ax[2].plot(g_rel_pow,np.arange(periodic_rel_power.shape[0])/10,label='gamma')\n",
    "ax[2].set_xlabel('Relative power')\n",
    "ax[2].legend()\n",
    "ax[2].set_ylim(1,0)\n",
    "ax[2].axhline(cov, lw=1, c=\"red\")\n",
    "vertex_val = [bigbrain_boundaries_list[i][ROI_combined_map[vertex]] for i in bigbrain_boundaries_list.keys()]\n",
    "ROI_mean = [np.mean(bigbrain_boundaries_list[i][ROI_combined_map]) for i in bigbrain_boundaries_list.keys()]\n",
    "ROI_std = [np.std(bigbrain_boundaries_list[i][ROI_combined_map]) for i in bigbrain_boundaries_list.keys()]\n",
    "max_smooth= np.max(np.abs(csd_smooth))\n",
    "divnorm = colors.TwoSlopeNorm(vmin=-max_smooth, vcenter=0, vmax=max_smooth)\n",
    "ax[3].set_title(\"Current Source Density\")\n",
    "im = ax[3].imshow(\n",
    "    csd_smooth, norm=divnorm, origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    "    extent=[\n",
    "        crop_times[epo_type][0], \n",
    "        crop_times[epo_type][-1], \n",
    "        1, 0\n",
    "    ],\n",
    "    cmap=\"RdBu_r\"\n",
    ")\n",
    "ax[3].set_ylim(1,0)\n",
    "cs = plt.cm.afmhot(np.linspace(0, 1, num=11))\n",
    "ax[3].axhline(cov, lw=1, c=\"red\")\n",
    "for l_ix, th in enumerate(np.cumsum(ROI_mean)):\n",
    "    ax[3].axhline(th, linestyle=(0, (5,5)), c=\"black\", lw=0.5)\n",
    "    ax[3].axhspan(th-ROI_std[l_ix], th+ROI_std[l_ix], alpha=0.05, color=\"black\", lw=0)\n",
    "    ax[3].annotate(layer_labels[l_ix],[-0.49, th-0.01],size=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "cr = plt.cm.cool(np.linspace(0, 1, num=11))\n",
    "for c_i, c in enumerate(cr):\n",
    "    ax.plot(freqs, psd_per_layer[c_i,vertex,:] , lw=1, alpha=1, c=c)\n",
    "    ax.plot(freqs, aperiodic_per_layer[c_i,vertex,:] , lw=1, alpha=1, c=c)\n",
    "ax.set_xlim(0,60)\n",
    "ax.axvline(7, linestyle=\"dashed\", lw=1, c=\"black\")\n",
    "ax.axvline(30, linestyle=\"dashed\", lw=1, c=\"black\")\n",
    "ax.axvline(50, linestyle=\"dashed\", lw=1, c=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7725bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex_val = [bigbrain_boundaries_list[i][ROI_combined_map][vertex] for i in bigbrain_boundaries_list.keys()]\n",
    "# bigbrain_boundaries_list[\"1\"][ROI_combined_map]\n",
    "bigbrain_boundaries_list[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e930bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = plt.cm.viridis(np.linspace(0, 1, num=10))\n",
    "values = cs[:,:3]\n",
    "gray = np.array([0.4, 0.4, 0.4])\n",
    "nan_c = np.array([1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_matrix = np.repeat(gray.reshape(1,-1), layer_len, axis=0)\n",
    "for c_ix, c in enumerate(values):\n",
    "    c_ix = c_ix+1\n",
    "    colour_matrix[ROI_indexes[\"L_4_ROI\"][crossover == c_ix]] = c\n",
    "colour_matrix[ROI_indexes[\"L_4_ROI\"][np.isnan(crossover)]] = nan_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.Trimesh(vertices=i_vertices, faces=i_faces, process=False, validate=False)\n",
    "mesh = mesh.as_open3d\n",
    "mesh.vertex_colors = o3d.utility.Vector3dVector(colour_matrix)\n",
    "mesh.compute_vertex_normals(normalized=True)\n",
    "o3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = FOOOF()\n",
    "fz.fit(freqs, psd_per_layer[0,1,:],[0,125])\n",
    "ffntr = fooofinator(freqs, psd_per_layer[0,1,:], [0.1,125])\n",
    "f, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax.plot(freqs, np.log10(psd_per_layer[0,1,:]), label=\"PSD\")\n",
    "ax.plot(freqs, fz._ap_fit, label=\"FOOOF\")\n",
    "ax.plot(freqs, ffntr, label=\"FOOOFINATOR\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31d77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fb399",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
